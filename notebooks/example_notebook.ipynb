{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Change Detection using a Pretrained Model and a Public Dataset\n",
    "\n",
    "This notebook demonstrates how to use the `change-detection` codebase to perform an end-to-end change detection task using a small, publicly available dataset. We will:\n",
    "\n",
    "- Download and prepare the LEVIR-CD dataset (a commonly used dataset for building change detection).\n",
    "- Preprocess the data.\n",
    "- Initialize the model using the provided codebase.\n",
    "- Train the model.\n",
    "- Evaluate the model.\n",
    "- Visualize some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (if not already installed)\n",
    "# !pip install torch torchvision matplotlib tqdm\n",
    "# !pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add the path to the change-detection codebase\n",
    "sys.path.append('/path/to/change-detection')  # Update this path accordingly\n",
    "\n",
    "# Import modules from the codebase\n",
    "from data.datasets import ChangeDetectionDataset, get_default_transforms\n",
    "from models.siamese_unet import SiameseUNet\n",
    "from train.loss_functions import DiceLoss\n",
    "from train.metrics import IoU, F1Score\n",
    "from train.trainer import CustomTrainer, TrainerConfig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and Prepare the Dataset\n",
    "\n",
    "We will use the **LEVIR-CD** dataset, which contains high-resolution images for building change detection tasks. For the sake of this demo, we'll use a small subset of the dataset.\n",
    "\n",
    "**Note**: Ensure you have the necessary permissions to download and use the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for data\n",
    "os.makedirs('data/LEVER-CD/train/images_before', exist_ok=True)\n",
    "os.makedirs('data/LEVER-CD/train/images_after', exist_ok=True)\n",
    "os.makedirs('data/LEVER-CD/train/labels', exist_ok=True)\n",
    "os.makedirs('data/LEVER-CD/val/images_before', exist_ok=True)\n",
    "os.makedirs('data/LEVER-CD/val/images_after', exist_ok=True)\n",
    "os.makedirs('data/LEVER-CD/val/labels', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, let's assume we've downloaded a few image pairs and labels\n",
    "# Normally, you would download and extract the dataset here\n",
    "# For this demo, we'll create some dummy data\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def create_dummy_image(path):\n",
    "    img = Image.new('RGB', (256, 256), color='white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.rectangle([50, 50, 200, 200], outline='black', fill='gray')\n",
    "    img.save(path)\n",
    "\n",
    "def create_dummy_label(path):\n",
    "    img = Image.new('L', (256, 256), color=0)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.rectangle([50, 50, 200, 200], fill=255)\n",
    "    img.save(path)\n",
    "\n",
    "# Create dummy training data\n",
    "for i in range(5):\n",
    "    create_dummy_image(f'data/LEVER-CD/train/images_before/image_{i}_before.png')\n",
    "    create_dummy_image(f'data/LEVER-CD/train/images_after/image_{i}_after.png')\n",
    "    create_dummy_label(f'data/LEVER-CD/train/labels/label_{i}.png')\n",
    "\n",
    "# Create dummy validation data\n",
    "for i in range(2):\n",
    "    create_dummy_image(f'data/LEVER-CD/val/images_before/image_{i}_before.png')\n",
    "    create_dummy_image(f'data/LEVER-CD/val/images_after/image_{i}_after.png')\n",
    "    create_dummy_label(f'data/LEVER-CD/val/labels/label_{i}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data Loaders\n",
    "\n",
    "We will use the `ChangeDetectionDataset` class from the codebase to create PyTorch datasets and data loaders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "train_before_paths = [f'data/LEVER-CD/train/images_before/image_{i}_before.png' for i in range(5)]\n",
    "train_after_paths = [f'data/LEVER-CD/train/images_after/image_{i}_after.png' for i in range(5)]\n",
    "train_label_paths = [f'data/LEVER-CD/train/labels/label_{i}.png' for i in range(5)]\n",
    "\n",
    "val_before_paths = [f'data/LEVER-CD/val/images_before/image_{i}_before.png' for i in range(2)]\n",
    "val_after_paths = [f'data/LEVER-CD/val/images_after/image_{i}_after.png' for i in range(2)]\n",
    "val_label_paths = [f'data/LEVER-CD/val/labels/label_{i}.png' for i in range(2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = ChangeDetectionDataset(\n",
    "    image_pairs=list(zip(train_before_paths, train_after_paths)),\n",
    "    labels=train_label_paths,\n",
    "    transform=get_default_transforms()\n",
    ")\n",
    "\n",
    "val_dataset = ChangeDetectionDataset(\n",
    "    image_pairs=list(zip(val_before_paths, val_after_paths)),\n",
    "    labels=val_label_paths,\n",
    "    transform=get_default_transforms()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize the Model\n",
    "\n",
    "We will use the `SiameseUNet` model from the codebase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = SiameseUNet(in_channels=3, out_channels=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Loss Function and Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and metrics\n",
    "loss_fn = DiceLoss()\n",
    "\n",
    "metrics = [\n",
    "    IoU(threshold=0.5),\n",
    "    F1Score(threshold=0.5)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set Up the Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define trainer configuration\n",
    "trainer_config = TrainerConfig(\n",
    "    num_epochs=5,\n",
    "    checkpoint_path=None,\n",
    "    checkpoint_dir='checkpoints/',\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=metrics,\n",
    "    config=trainer_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train(train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate the Model\n",
    "\n",
    "After training, we can evaluate the model on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize metrics\n",
    "for metric in metrics:\n",
    "    metric.reset()\n",
    "\n",
    "# Run evaluation\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = [input_tensor.to(trainer.device) for input_tensor in inputs]\n",
    "        targets = targets.to(trainer.device)\n",
    "        outputs = model(*inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        for metric in metrics:\n",
    "            metric.update(outputs, targets)\n",
    "\n",
    "# Compute and print metrics\n",
    "for metric in metrics:\n",
    "    metric_value = metric.compute()\n",
    "    print(f'{metric.__class__.__name__}: {metric_value:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Some Results\n",
    "\n",
    "Let's visualize some predictions from the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images\n",
    "def show_images(images, titles=None):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        img = images[i]\n",
    "        if img.ndim == 2:\n",
    "            plt.imshow(img, cmap='gray')\n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        if titles:\n",
    "            plt.title(titles[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from validation loader\n",
    "inputs, targets = next(iter(val_loader))\n",
    "inputs = [input_tensor.to(trainer.device) for input_tensor in inputs]\n",
    "targets = targets.to(trainer.device)\n",
    "\n",
    "# Get model predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(*inputs)\n",
    "\n",
    "# Move tensors to CPU and convert to numpy arrays\n",
    "before_image = inputs[0].cpu().numpy()[0].transpose(1, 2, 0)\n",
    "after_image = inputs[1].cpu().numpy()[0].transpose(1, 2, 0)\n",
    "target = targets.cpu().numpy()[0, 0]\n",
    "prediction = torch.sigmoid(outputs).cpu().numpy()[0, 0] > 0.5\n",
    "\n",
    "# Display images\n",
    "show_images(\n",
    "    [before_image, after_image, target, prediction],\n",
    "    titles=['Before Image', 'After Image', 'Ground Truth', 'Prediction']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have demonstrated an end-to-end change detection workflow using the provided codebase and a small dataset. This includes data preparation, model training, evaluation, and visualization of results.\n",
    "\n",
    "For a production environment, you would use the full dataset and potentially more advanced models and training configurations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
